[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I am currently the Data Scientist at the Dangote Industries Limited and I also served as the Analytics faculty member with BNet Learning.\n\nResearch Interests\n\nEnvironmental Statistics\nGeocomputation\nMachine Learning\nData Science\nExperimental Design\nMobile Data Collection\n\n\n\nData Stack\n\n\nData Tool Box\n- R | Python | Julia | SQL | Excel | ODK\n\n\n\n\n\n\n\nDevelopment Environments\n- Rstudio | Jupyter | VS Code | Pluto | Literate Programming with Quarto and Rmarkdown\n\n\n\n\n\n\n\nDatabases\n- PostgreSQL | Elasticsearch\n\n\n\n\n\n\n\nBI Tools\n- PowerBI | Looker Studio | Tableau | Kibana\n\n\n\n\n\n\n\nOperating Systems\n- Windows | Ubuntu | CentOS\n\n\n\n\n\n\n\nEducation\n\n\nUniversity of Ibadan\nMSc in Statistics\nAdvisor: Prof. K.O. Obisesan\n\n\nIbadan, Nigeria\nGranted March 2015\n\n\n\nDissertation: Extreme Value Model for Rainfall Distribution\nResearch Area: Environmental Statistics\nObtained PhD Grade\n\n\n\nFederal University of Technology, Akure\nB.Tech in Industrial Mathematics\n\n\nAkure, Nigeria\nGranted September 2010\n\n\n\n\nExperience\n\n\nDangote Industries Limited\n\n\n2022 - present\n\n\nData Scientist\n\nOrchestrated a data pipeline from a third party system.\nImplemented an extensive ETL process.\nContinuous mining of the transformed data.\nDeveloped and monitor ML models using tidymodels methodology in R.\n\n\n\n\nLongbridge Technologies Limited\n\n\n2019 - 2021\n\n\nHead, Business Transformation & Operational Excellence\n\nWorked in a cross-functional environment with various business groups, and end-users to identify, document, and communicate business processes.\nCreated a system to evaluate the success of any adjustments made within the organization and present findings.\nCommunicated strategies and objectives with relevant departments and colleagues.\n\n\n\neHealth Systems Africa\n\n\n2017 - 2018\n\n\nData Scientist\n\nDeveloped models to discover the patterns and information in vast amounts of spatial and non-spatial data across several programs at eHA to support better programmatic decisions, intervention planning and improved information products.\nApplied data mining techniques, performed statistical analysis, and build high quality prediction models that formed core of eHA’s information products on disease surveillance in particular.\n\n\n\nVenture Garden Group\n\n\n2016-2017\n\n\nData Scientist\n\nLead discovery processes with Institute stakeholders to identify the business requirements and the expected outcome.\nConducted advanced data analysis and complex designs algorithm.\nApplied advanced statistical and predictive modeling techniques to build, maintain, and improve on multiple real-time decision systems.\nValidated analysis using scenario modeling.\n\n\n\nComputer Warehouse Group, Plc\n\n\n2013-2016\n\n\nQuality Assurance Analyst\n\nEncouraged factual approach to decision making by providing the management an accurate analysis of people and processes.\nAchieved success in providing standard value-added metrics for business model.\nConducted quality spot checks of project implementations & Services (Software, Hardware, Communication).\nProvided both administrative and analytic support to departments in order to manage critical and people sensitive projects.\nCollaborated with the VP of Sales in the development of sales forecasts and projections.\nSummarized and report performance against sales quotas to all sales personnel in a timely manner.\nProactively prepare and deliver ad hoc customer analysis to sales team members and senior management.\n\n\n\nPractical Sampling International\n\n\n2012-2013\n\n\nData Analyst\n\nSupervised the data collection process of many high profile projects.\nProcessed and analyzed raw data collected from field work.\nImproved the statistical procedure usage and reporting method.\n\n\n\nTeaching\n\nCodementor.io\n\n\nData Analytics Mentor\n\n\n2018-present\n\n\n\n\nBNet Learning\n\n\nData Analytics Faculty\n\n\n2018-present\n\n\n\n\nEduPristine\n\n\nGuest Faculty, Business Analytics\n\n\n2015-2016\n\n\n\n\nAfriHUB Nigeria\n\n\nGuest Faculty IBM SPSS\n\n\n2011-2012"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Creating Animated Visualization in R\n\n\n\n\n\n\n\nAnimation\n\n\nVisualization\n\n\nggplot\n\n\nR\n\n\ngganimate\n\n\n\n\nIn this blog post, I would demonstrate how to create an animated visualizations in R using the gapminder dataset from the gapminder package in R.\n\n\n\n\n\n\nJan 26, 2023\n\n\nOlumide Oyalola\n\n\n\n\n\n\n\n\nWorking with the OSRM API\n\n\n\n\n\n\n\nCode\n\n\nAnalysis\n\n\nGIS\n\n\nR\n\n\nRouting\n\n\nOpen Street Map (osrm)\n\n\n\n\nIn this blog post, I would demonstrate how I used the osrm package in R to return the distance and travel time between a destination and different sources\n\n\n\n\n\n\nOct 19, 2022\n\n\nOlumide Oyalola\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Olumide Oyalola",
    "section": "",
    "text": "I am a data professional. I have extensive background working with varied data sets and using advanced analytics to enable business stakeholders to make informed decisions.\nI’ve since had engagements in various sectors spanning IT services, FMCG, Information services, and health interventions. I have a great communication and people management skills. I make time for freelance projects that are engaging and challenging!\nContact me on Codementor"
  },
  {
    "objectID": "posts/osrm-post/index.html",
    "href": "posts/osrm-post/index.html",
    "title": "Working with the OSRM API",
    "section": "",
    "text": "An interface between R and the OSRM (OpenStreetMap-Based Routing Service) API. OSRM is a routing service based on OpenStreetMap data. See for more information. This package allows to compute routes, trips, isochrones and travel distances matrices (travel time in minutes and distance in kilometer).\nThe package is available on CRAN and it can be installed by running the code chunk below from the Rstudio console.\nFor the purpose of this post, the osrmTable function from the osrm package in R would be used to return the distance in meter and the travel time in minutes.\n\nCode#install.packages(\"osrm\")"
  },
  {
    "objectID": "posts/osrm-post/index.html#load-packages",
    "href": "posts/osrm-post/index.html#load-packages",
    "title": "Working with the OSRM API",
    "section": "Load Packages",
    "text": "Load Packages\n\nCode# Install pacman package if needed\n#if(!require(\"pacman\")) install.packages(\"pacman\")\n\n# load the required packages\n\npacman::p_load(\n  httr,\n  jsonlite,\n  tidyjson,\n  tidyverse,\n  lubridate,\n  geosphere,\n  anytime,\n  tictoc,\n  stringi,\n  maptools,\n  geosphere,\n  sf,\n  sp,\n  openxlsx,\n  leaflet,\n  magrittr,\n  janitor,\n  arrow,\n  osrm\n)\n\n\nLoad Data\n\nCode# load  file as tibble\n\ntic(\"Load the csv file\")\n\ndf <- read_parquet(\"ml_data.parquet\")\n\ntoc()\n\nLoad the csv file: 0.22 sec elapsed"
  },
  {
    "objectID": "posts/osrm-post/index.html#data-munging",
    "href": "posts/osrm-post/index.html#data-munging",
    "title": "Working with the OSRM API",
    "section": "Data Munging",
    "text": "Data Munging\n\nCoderemove <- c(\"/Date\", \"(\", \")/\", \"[[:punct:]]\")\n\nvar <- c(\"ActualSpeed\", \"Address\", \"Altitude\", \"AssetClass\", \"AssetLocationID\", \"AssetStatus\", \"CategoryID\", \"CategoryName\", \"City\", \"CustomerName\", \"DateTimeLocal\", \"DateTimeReceived\", \"DeliveryOrderNumber\", \"DepartureDateTime\", \"DestinationArea\", \"DestinationCity\", \"DestinationSite\", \"DestinationStreet\", \"DeviceType\", \"DirectionString\", \"Distance\", \"DriverCode\", \"DriverID\", \"Geofence\", \"IgnitionStatus\", \"Information\", \"JourneyDistance\", \"JourneyDuration\", \"JourneyIdleTime\", \"JourneyMaxSpeed\", \"LastIgnitionOff\", \"LastIgnitionOn\", \"Latitude\", \"Load\", \"Longitude\", \"NumSatellites\", \"Odometer\", \"Reason\", \"ReasonString\", \"Reference\", \"Region\", \"SiteName\", \"SpeedOverGround\", \"Status\", \"Street\", \"TrackTrue\", \"TripDestination\", \"TripID\", \"TripSource\", \"TripType\", \"UTCDateTime\", \"WaybillNumber\")\n\n\n\nCode# data cleaning\n\ndf %<>% \n  #dplyr::select(tidyselect::all_of(var)) %>% \n  mutate(DateTimeLocal = str_remove_all(`DateTimeLocal`, \n                                        paste(remove, collapse = \"|\")),\n         DateTimeLocal = str_remove_all(`DateTimeLocal`, \n                                        \"\\\\+0100|\\\\+0000\"),\n         DateTimeLocal = as.numeric(`DateTimeLocal`),\n         DateTimeLocal = `DateTimeLocal`/1000,\n         DateTimeLocal = anytime(`DateTimeLocal`),\n         DateTimeReceived = str_remove_all(DateTimeReceived, \n                                           paste(remove, collapse = \"|\")),\n         DateTimeReceived = str_remove_all(DateTimeReceived, \n                                           \"\\\\+0100|\\\\+0000\"),\n         DateTimeReceived = as.numeric(DateTimeReceived),\n         DateTimeReceived = DateTimeReceived/1000,\n         DateTimeReceived = anytime(DateTimeReceived),\n         DepartureDateTime = str_remove_all(DepartureDateTime, \n                                            paste(remove, collapse = \"|\")),\n         DepartureDateTime = str_remove_all(DepartureDateTime, \n                                            \"\\\\+0100|\\\\+0000\"),\n         DepartureDateTime = as.numeric(DepartureDateTime),\n         DepartureDateTime = DepartureDateTime/1000,\n         DepartureDateTime = anytime(DepartureDateTime),\n         UTCDateTime = str_remove_all(UTCDateTime, \n                                      paste(remove, collapse = \"|\")),\n         UTCDateTime = str_remove_all(UTCDateTime, \n                                      \"\\\\+0100|\\\\+0000\"),\n         UTCDateTime = as.numeric(UTCDateTime),\n         UTCDateTime = UTCDateTime/1000,\n         UTCDateTime = anytime(UTCDateTime),\n         LastIgnitionOff = str_remove_all(LastIgnitionOff, \n                                          paste(remove, collapse = \"|\")),\n         LastIgnitionOff = str_remove_all(LastIgnitionOff, \n                                          \"\\\\+0100|\\\\+0000\"),\n         LastIgnitionOff = as.numeric(LastIgnitionOff),\n         LastIgnitionOff = LastIgnitionOff/1000,\n         LastIgnitionOff = anytime(LastIgnitionOff),\n         LastIgnitionOn = str_remove_all(LastIgnitionOn, \n                                         paste(remove, collapse = \"|\")),\n         LastIgnitionOn = str_remove_all(LastIgnitionOn, \n                                         \"\\\\+0100|\\\\+0000\"),\n         LastIgnitionOn = as.numeric(LastIgnitionOn),\n         LastIgnitionOn = LastIgnitionOn/1000,\n         LastIgnitionOn = anytime(LastIgnitionOn)) %>% \n  filter(!between(TripID, 9000000000, Inf)) %>% \n  filter(!TripID == 0)\n\ndf %<>% mutate(TripID = as.numeric(TripID))\n\n\n\nCodeoptions(scipen = 999)\n\n# destination dataframe\n\nibese_df <- data.frame(id = \"ibese\", lon = c(3.043568), lat = c(7.006293))\n\n\nibese <- matrix(c(3.043568,7.006293), ncol = 2)\n\nibese_geofence <- c(\"Ibese\", \"IBESE\", \"Vehicle Park\", \"Vehicle Park 2\")\n\n\nDetermining the direction of the truck\n\nCodeinbound_df <- df %>% \n  filter(AssetStatus == \"InService\", Longitude > 0, \n         Latitude > 0) %>% \n  filter(!between(TripID, 9000000000, Inf)) %>% \n  filter(TripID != 0) %>% \n  select(Reference, DateTimeReceived, \n         Longitude, Latitude, TripID, Geofence, Altitude) %>% \n  arrange(Reference, DateTimeReceived) %>% \n  group_by(Reference, TripID) %>% \n  mutate(.after = DateTimeReceived,\n         TimeDiff = as.numeric(difftime(DateTimeReceived, \n                                        lag(DateTimeReceived, \n                                            default = first(DateTimeReceived)), \n                                        units = \"hours\")),\n         LongLat = matrix(c(Longitude, Latitude), ncol = 2),\n         DistCovered = distGeo(LongLat, lag(LongLat)),\n         DistCovered = DistCovered/1000,\n         DistToPlant = distGeo(LongLat, ibese),\n         DistToPlant = DistToPlant/1000) %>%\n  mutate(Direction = if_else(lag(DistToPlant) < DistToPlant, \"Inbound\", \"Outbound\")) %>% \n  filter(Direction == \"Inbound\") %>% \n  slice_tail(n = 1) %>% \n  filter(TripID != 3000071349)\n\n\nEstimating the arrival time and distance\n\nCodeduration <- osrmTable(src = df %>%\n                        # filter(as.Date(DateTimeReceived) == today()) %>% \n                        select(TripID, Longitude, Latitude) %>% \n                        slice_head(n = 100),\n                      dst = ibese_df, measure = \"duration\", osrm.profile = \"car\")\n\n\ndistance <- osrmTable(src = df %>%\n                        # filter(as.Date(DateTimeReceived) == today()) %>% \n                        select(TripID, Longitude, Latitude) %>% \n                        slice_head(n = 100),\n                      dst = ibese_df, measure = \"distance\", osrm.profile = \"car\")\n\n\ndistances <- distance$distances %>% \n  as.data.frame() %>%\n  rownames_to_column() %>% \n  rename(TripID = rowname,\n         Distance = ibese) %>% \n  mutate(TripID = as.numeric(TripID))\n\n\ndurations <- duration$durations %>% \n  as.data.frame() %>%\n  rownames_to_column() %>% \n  rename(TripID = rowname,\n         duration = ibese) %>% \n  mutate(TripID = as.numeric(TripID))"
  },
  {
    "objectID": "posts/osrm-post/index.html#data-join",
    "href": "posts/osrm-post/index.html#data-join",
    "title": "Working with the OSRM API",
    "section": "Data Join",
    "text": "Data Join\nJoining the durations, distances and inbound_df data frames.\n\nCodearrival <- df %>%\n  inner_join(durations, by = 'TripID') %>% \n  inner_join(distances, by = 'TripID') %>% \n  mutate(Arrival = DateTimeReceived + minutes(round(duration))) %>% \n  select(TripID, Reference, Longitude, Latitude, Distance, DateTimeReceived, Arrival) %>% \n  arrange(Distance)\n\n#DT::datatable(arrival)"
  },
  {
    "objectID": "posts/plot-animation-post/index.html",
    "href": "posts/plot-animation-post/index.html",
    "title": "Creating Animated Visualization in R",
    "section": "",
    "text": "Static visualizations that are publication ready are readily available in R using the ggplot2 package. However, there are times where it’s required to illustrate the change in an event overtime. This is a particular use case of the gganimate package in R which is an extension of the ggplot2 package for creating animated ggplots.\nIt provides a range of functionalities that can be added to the plot object in order to customize how it should change with time.\nThe gganimate package is available on CRAN and it can be installed by running the code chunk below from the Rstudio console.\n\nCodeinstall.packages(\"gganimate\")\n\n\n\nThe gapminder dataset in R is an excerpt of the Gapminder data on life expectancy, GDP per capita, and population by country.\nThe gapminder package is available on CRAN and it can be installed by running the code chunk below from the Rstudio console.\n\nCodeinstall.packages(\"gapminder\")"
  },
  {
    "objectID": "posts/plot-animation-post/index.html#load-packages",
    "href": "posts/plot-animation-post/index.html#load-packages",
    "title": "Creating Animated Visualization in R",
    "section": "Load Packages",
    "text": "Load Packages\n\nCodeif(!require(pacman)) install.packages(\"pacman\")\n\nLoading required package: pacman\n\n\nWarning: package 'pacman' was built under R version 4.0.5\n\nCodepacman::p_load(\n  tidyverse,\n  gganimate,\n  gapminder\n)\n\ntheme_set(theme_bw())"
  },
  {
    "objectID": "posts/plot-animation-post/index.html#load-demo-dataset",
    "href": "posts/plot-animation-post/index.html#load-demo-dataset",
    "title": "Creating Animated Visualization in R",
    "section": "Load Demo Dataset",
    "text": "Load Demo Dataset\n\nCodedata(gapminder)\n\n\nA closer look at the dataset\n\nIf you’re new to the gapminder dataset, below is the structure of the dataset which includes the variables and sample data.\n\n\nCodeglimpse(gapminder)\n\nRows: 1,704\nColumns: 6\n$ country   <fct> \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", \"Afghanistan\", ~\n$ continent <fct> Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, ~\n$ year      <int> 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, ~\n$ lifeExp   <dbl> 28.801, 30.332, 31.997, 34.020, 36.088, 38.438, 39.854, 40.8~\n$ pop       <int> 8425333, 9240934, 10267083, 11537966, 13079460, 14880372, 12~\n$ gdpPercap <dbl> 779.4453, 820.8530, 853.1007, 836.1971, 739.9811, 786.1134, ~"
  },
  {
    "objectID": "posts/plot-animation-post/index.html#static-plot",
    "href": "posts/plot-animation-post/index.html#static-plot",
    "title": "Creating Animated Visualization in R",
    "section": "Static Plot",
    "text": "Static Plot\n\nCodep <- ggplot(\n  gapminder, \n  aes(x = gdpPercap, y=lifeExp, size = pop, colour = country)\n  ) +\n  geom_point(show.legend = FALSE, alpha = 0.7) +\n  scale_color_viridis_d() +\n  scale_size(range = c(2, 12)) +\n  scale_x_continuous(labels = scales::comma) +\n  labs(x = \"GDP per capita\", y = \"Life expectancy\")\np"
  },
  {
    "objectID": "posts/plot-animation-post/index.html#transition-through-distinct-states-in-time",
    "href": "posts/plot-animation-post/index.html#transition-through-distinct-states-in-time",
    "title": "Creating Animated Visualization in R",
    "section": "Transition through distinct states in time",
    "text": "Transition through distinct states in time\nBasics\nKey R function: transition_time().\n\nThe transition length between the states will be set to correspond to the actual time difference between them.\n\nLabel variables: frame_time.\n\nGives the time that the current frame corresponds to.\n\n\nCodep + transition_time(year) +\n  labs(title = \"Year: {frame_time}\")\n\nWarning: No renderer available. Please install the gifski, av, or magick\npackage to create animated output\n\n\nNULL\n\n\nCreate facets by continent:\n\nCodep + facet_wrap(~continent) +\n  transition_time(year) +\n  labs(title = \"Year: {frame_time}\")\n\nWarning: No renderer available. Please install the gifski, av, or magick\npackage to create animated output\n\n\nNULL\n\n\nLet the view follow the data in each frame\n\nCodep + transition_time(year) +\n  labs(title = \"Year: {frame_time}\") +\n  view_follow(fixed_y = TRUE)\n\nWarning: No renderer available. Please install the gifski, av, or magick\npackage to create animated output\n\n\nNULL\n\n\n\nCodepop_ng <- gapminder %>% \n  filter(country == \"Nigeria\") %>% \n  ggplot(aes(x = year, y = pop, fill = pop)) +\n  geom_bar(stat = \"identity\", show.legend = FALSE) +\n  scale_fill_distiller(palette = \"Reds\", direction = 1) +\n  theme_minimal() +\n  theme(\n    panel.grid = element_blank(),\n    panel.grid.major.y = element_line(color = \"white\"),\n    panel.ontop = TRUE\n  ) +\n  scale_y_continuous(labels = scales::unit_format(unit = \"M\", scale = 1e-6)) +\n  geom_text(aes(label = paste0(round(pop/1000000,1), \"M\")))\n\npop_ng\n\n\n\n\n\nCodepop_ng + transition_time(year) +\n  shadow_mark() +\n  labs(x = \"Year\",\n       y = \"Population\",\n       title = \"Year: {frame_time}\")\n\nWarning: No renderer available. Please install the gifski, av, or magick\npackage to create animated output\n\n\nNULL"
  },
  {
    "objectID": "posts/plot-animation-post/index.html#save-animation",
    "href": "posts/plot-animation-post/index.html#save-animation",
    "title": "Creating Animated Visualization in R",
    "section": "Save Animation",
    "text": "Save Animation\nIf you need to save the animation for later use you can use the anim_save() function."
  },
  {
    "objectID": "posts/plot-animation-post/index.html#read-more",
    "href": "posts/plot-animation-post/index.html#read-more",
    "title": "Creating Animated Visualization in R",
    "section": "Read more",
    "text": "Read more\n\ngganimate package official documentation"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Olumide Oyalola",
    "section": "",
    "text": "An exploratory analysis on the global obesity prevalence. I used flexdashboard to present the analysis! An annual data from 1975 to 2014 was explored. …. Continue reading"
  },
  {
    "objectID": "projects.html#us-energy-analysis",
    "href": "projects.html#us-energy-analysis",
    "title": "Olumide Oyalola",
    "section": "US Energy Analysis",
    "text": "US Energy Analysis\n\n\n\n\n\n\nExploratory analysis of the annual US crude oil import prices … Link to the flexdashboard"
  }
]